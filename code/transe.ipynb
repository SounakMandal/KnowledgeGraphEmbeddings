{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65e125ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T06:55:35.888561Z",
     "iopub.status.busy": "2023-04-17T06:55:35.888095Z",
     "iopub.status.idle": "2023-04-17T06:55:46.502874Z",
     "shell.execute_reply": "2023-04-17T06:55:46.501461Z"
    },
    "papermill": {
     "duration": 10.623851,
     "end_time": "2023-04-17T06:55:46.505774",
     "exception": false,
     "start_time": "2023-04-17T06:55:35.881923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rdflib\r\n",
      "  Downloading rdflib-6.3.2-py3-none-any.whl (528 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m528.1/528.1 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata<5.0.0,>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from rdflib) (4.11.4)\r\n",
      "Collecting isodate<0.7.0,>=0.6.0\r\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pyparsing<4,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from rdflib) (3.0.9)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0.0,>=4.0.0->rdflib) (3.11.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0.0,>=4.0.0->rdflib) (4.4.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from isodate<0.7.0,>=0.6.0->rdflib) (1.16.0)\r\n",
      "Installing collected packages: isodate, rdflib\r\n",
      "Successfully installed isodate-0.6.1 rdflib-6.3.2\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install rdflib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d856f743",
   "metadata": {
    "papermill": {
     "duration": 0.003458,
     "end_time": "2023-04-17T06:55:46.513354",
     "exception": false,
     "start_time": "2023-04-17T06:55:46.509896",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09839bd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T06:55:46.522488Z",
     "iopub.status.busy": "2023-04-17T06:55:46.522162Z",
     "iopub.status.idle": "2023-04-17T06:55:46.957429Z",
     "shell.execute_reply": "2023-04-17T06:55:46.956429Z"
    },
    "papermill": {
     "duration": 0.4426,
     "end_time": "2023-04-17T06:55:46.959720",
     "exception": false,
     "start_time": "2023-04-17T06:55:46.517120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import rdflib\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "class TriplesDataset:\n",
    "    def __init__(self, url_list: str) -> None:\n",
    "        datapoints = []\n",
    "        labels = []\n",
    "        entities = set()\n",
    "        relations = set()\n",
    "        \n",
    "        for url in url_list:\n",
    "            graph_variable = rdflib.Graph()\n",
    "            resultGraph = graph_variable.parse(url)\n",
    "            for subject_item, predicate, object_item in resultGraph.triples((None, None, None)):\n",
    "                if type(object_item) != rdflib.term.URIRef:\n",
    "                    continue\n",
    "                \n",
    "                # add them to entities and relations\n",
    "                entities.add(str(subject_item))\n",
    "                entities.add(str(object_item))\n",
    "                relations.add(str(predicate))\n",
    "                \n",
    "                # add them to datapoints\n",
    "                datapoints.append(\n",
    "                    tuple([str(subject_item), str(predicate), str(object_item)])\n",
    "                )\n",
    "                labels.append(predicate)\n",
    "        \n",
    "        self.entities = list(entities)\n",
    "        self.relations = list(relations)\n",
    "        self.datapoints = datapoints\n",
    "        \n",
    "    def construct_hash(self):\n",
    "        entity_hash = dict()\n",
    "        for index, entity in enumerate(self.entities):\n",
    "            entity_hash[entity] = index\n",
    "        \n",
    "        relation_hash = dict()\n",
    "        for index, relation in enumerate(self.relations):\n",
    "            relation_hash[relation] = index\n",
    "        return entity_hash, relation_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f9f2f6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T06:55:46.968627Z",
     "iopub.status.busy": "2023-04-17T06:55:46.968343Z",
     "iopub.status.idle": "2023-04-17T06:56:43.560781Z",
     "shell.execute_reply": "2023-04-17T06:56:43.559721Z"
    },
    "papermill": {
     "duration": 56.599843,
     "end_time": "2023-04-17T06:56:43.563584",
     "exception": false,
     "start_time": "2023-04-17T06:55:46.963741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_file_path = [\n",
    "    \"/kaggle/input/bgs-dataset/625KGeologyMap_all.nt\",\n",
    "    \"/kaggle/input/bgs-dataset/dataholdings.nt\",\n",
    "    \"/kaggle/input/bgs-dataset/earth-material-class.nt\",\n",
    "    \"/kaggle/input/bgs-dataset/geochronology.nt\",\n",
    "    \"/kaggle/input/bgs-dataset/lexicon-named-rock-unit.nt\"\n",
    "]\n",
    "dataset = TriplesDataset(data_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cb57e6",
   "metadata": {
    "papermill": {
     "duration": 0.00348,
     "end_time": "2023-04-17T06:56:43.571264",
     "exception": false,
     "start_time": "2023-04-17T06:56:43.567784",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generate Negative Samples for training #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f51976fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T06:56:43.580768Z",
     "iopub.status.busy": "2023-04-17T06:56:43.579727Z",
     "iopub.status.idle": "2023-04-17T06:56:43.590962Z",
     "shell.execute_reply": "2023-04-17T06:56:43.589925Z"
    },
    "papermill": {
     "duration": 0.018297,
     "end_time": "2023-04-17T06:56:43.593287",
     "exception": false,
     "start_time": "2023-04-17T06:56:43.574990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " def generate_negative_samples(dataset, positive_samples):\n",
    "    entities = set(dataset.entities)\n",
    "    entities_count = len(entities)\n",
    "    links_set = set(dataset.datapoints)\n",
    "    negative_samples = set()\n",
    "    \n",
    "    heads, predicates, tails = positive_samples\n",
    "    for triple in zip(heads, predicates, tails):\n",
    "        subject_item, predicate, object_item = triple\n",
    "        choice = random.sample([0, 1], 1)[0]\n",
    "        if choice == 0:\n",
    "            while True:\n",
    "                index = random.sample(range(entities_count), 1)[0]\n",
    "                corrupted_triple = tuple([dataset.entities[index], predicate, object_item])\n",
    "                if corrupted_triple not in links_set and corrupted_triple not in negative_samples:\n",
    "                    negative_samples.add(corrupted_triple)\n",
    "                    break\n",
    "        else:\n",
    "            while True:\n",
    "                index = random.sample(range(entities_count), 1)[0]\n",
    "                corrupted_triple = tuple([subject_item, predicate, dataset.entities[index]])\n",
    "                if corrupted_triple not in links_set and corrupted_triple not in negative_samples:\n",
    "                    negative_samples.add(corrupted_triple)\n",
    "                    break\n",
    "    return list(negative_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5e3086",
   "metadata": {
    "papermill": {
     "duration": 0.003805,
     "end_time": "2023-04-17T06:56:43.600820",
     "exception": false,
     "start_time": "2023-04-17T06:56:43.597015",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TransE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6149a18a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-17T06:56:43.609769Z",
     "iopub.status.busy": "2023-04-17T06:56:43.609432Z",
     "iopub.status.idle": "2023-04-17T06:56:45.667088Z",
     "shell.execute_reply": "2023-04-17T06:56:45.666052Z"
    },
    "papermill": {
     "duration": 2.064921,
     "end_time": "2023-04-17T06:56:45.669543",
     "exception": false,
     "start_time": "2023-04-17T06:56:43.604622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TransE(nn.Module):\n",
    "    def __init__(self, num_entities, num_relations, embedding_dim, hashing, margin):\n",
    "        super(TransE, self).__init__()\n",
    "        self.num_entities = num_entities\n",
    "        self.num_relations = num_relations\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.entity_hash = hashing[0]\n",
    "        self.relation_hash = hashing[1]\n",
    "        self.margin = margin\n",
    "        \n",
    "        # define entity and relation embeddings\n",
    "        self.entity_embeddings = nn.Embedding(num_entities, embedding_dim)\n",
    "        self.relation_embeddings = nn.Embedding(num_relations, embedding_dim)\n",
    "        \n",
    "        # initialize embeddings\n",
    "        nn.init.xavier_uniform_(self.entity_embeddings.weight.data)\n",
    "        nn.init.xavier_uniform_(self.relation_embeddings.weight.data)\n",
    "    \n",
    "    def _calculate_loss(self, triples):\n",
    "        score = []\n",
    "        for triple in triples:\n",
    "            head, relation, tail = triple\n",
    "            head_embedding = self.entity_embeddings(torch.tensor(self.entity_hash[head]))\n",
    "            relation_embedding = self.relation_embeddings(torch.tensor(self.relation_hash[relation]))\n",
    "            tail_embedding = self.entity_embeddings(torch.tensor(self.entity_hash[tail]))\n",
    "            distance = torch.linalg.norm(head_embedding + relation_embedding - tail_embedding)\n",
    "            score.append(distance)\n",
    "        return torch.tensor(score)\n",
    "    \n",
    "    def forward(self, positive_triples, negative_triples):\n",
    "        heads, predicates, tails = positive_triples\n",
    "        positive_score = self._calculate_loss(zip(heads, predicates, tails))\n",
    "        negative_score = self._calculate_loss(negative_triples)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = torch.mean(torch.max(\n",
    "            torch.zeros_like(negative_score), \n",
    "            self.margin + positive_score - negative_score\n",
    "        ))\n",
    "        loss.requires_grad = True\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd0982c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T06:56:45.678719Z",
     "iopub.status.busy": "2023-04-17T06:56:45.678189Z",
     "iopub.status.idle": "2023-04-17T06:56:45.683897Z",
     "shell.execute_reply": "2023-04-17T06:56:45.682858Z"
    },
    "papermill": {
     "duration": 0.012568,
     "end_time": "2023-04-17T06:56:45.686003",
     "exception": false,
     "start_time": "2023-04-17T06:56:45.673435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    for positive_triples in train_loader:\n",
    "        negative_triples = generate_negative_samples(dataset, positive_triples)\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(positive_triples, negative_triples)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fdd7191",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T06:56:45.694467Z",
     "iopub.status.busy": "2023-04-17T06:56:45.694204Z",
     "iopub.status.idle": "2023-04-17T06:56:45.701832Z",
     "shell.execute_reply": "2023-04-17T06:56:45.700963Z"
    },
    "papermill": {
     "duration": 0.014286,
     "end_time": "2023-04-17T06:56:45.703873",
     "exception": false,
     "start_time": "2023-04-17T06:56:45.689587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, dataset, loader, optimizer):\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    \n",
    "    patience = 5\n",
    "    best_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "    for epoch in range(100):\n",
    "        running_loss = train(model, optimizer, loader)\n",
    "        epoch_loss = running_loss / len(loader)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}, Loss: {epoch_loss:.6f}\")\n",
    "        \n",
    "        # Save the model\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            epochs_without_improvement = 0\n",
    "            torch.save(model.state_dict(), \"transeEmbeddings.pth\")\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement == patience:\n",
    "                print(f'Early stopping after {epoch + 1} epochs')\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "905825b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T06:56:45.712886Z",
     "iopub.status.busy": "2023-04-17T06:56:45.711840Z",
     "iopub.status.idle": "2023-04-17T06:56:45.717437Z",
     "shell.execute_reply": "2023-04-17T06:56:45.716572Z"
    },
    "papermill": {
     "duration": 0.012016,
     "end_time": "2023-04-17T06:56:45.719485",
     "exception": false,
     "start_time": "2023-04-17T06:56:45.707469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "positive_samples = dataset.datapoints\n",
    "\n",
    "# make dataloaders\n",
    "loader = DataLoader(positive_samples, batch_size=4096, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dbb6f91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T06:56:45.728341Z",
     "iopub.status.busy": "2023-04-17T06:56:45.727541Z",
     "iopub.status.idle": "2023-04-17T06:56:45.842383Z",
     "shell.execute_reply": "2023-04-17T06:56:45.841362Z"
    },
    "papermill": {
     "duration": 0.12188,
     "end_time": "2023-04-17T06:56:45.845002",
     "exception": false,
     "start_time": "2023-04-17T06:56:45.723122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "num_entities = len(dataset.entities)\n",
    "num_relations = len(dataset.relations)\n",
    "embedding_dim = 100\n",
    "hashing = dataset.construct_hash()\n",
    "margin = 0.4\n",
    "model = TransE(num_entities, num_relations, embedding_dim, hashing, margin)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d8c46b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T06:56:45.854101Z",
     "iopub.status.busy": "2023-04-17T06:56:45.853803Z",
     "iopub.status.idle": "2023-04-17T07:09:16.371898Z",
     "shell.execute_reply": "2023-04-17T07:09:16.370820Z"
    },
    "papermill": {
     "duration": 750.529396,
     "end_time": "2023-04-17T07:09:16.378266",
     "exception": false,
     "start_time": "2023-04-17T06:56:45.848870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.400072\n",
      "Epoch 2, Loss: 0.400062\n",
      "Epoch 3, Loss: 0.400057\n",
      "Epoch 4, Loss: 0.400082\n",
      "Epoch 5, Loss: 0.400087\n",
      "Epoch 6, Loss: 0.400063\n",
      "Epoch 7, Loss: 0.400068\n",
      "Epoch 8, Loss: 0.400052\n",
      "Epoch 9, Loss: 0.400028\n",
      "Epoch 10, Loss: 0.400078\n",
      "Epoch 11, Loss: 0.400045\n",
      "Epoch 12, Loss: 0.400071\n",
      "Epoch 13, Loss: 0.400073\n",
      "Epoch 14, Loss: 0.400076\n",
      "Early stopping after 14 epochs\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(model, dataset, loader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2812ac6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 830.33124,
   "end_time": "2023-04-17T07:09:17.625792",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-17T06:55:27.294552",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
